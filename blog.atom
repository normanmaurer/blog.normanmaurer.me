<?xml version="1.0" encoding="utf-8" ?>
<feed xml:lang="en-US" xmlns="http://www.w3.org/2005/Atom">
  <id>http://normanmaurer.me/</id>
  <title>Normans rant's and more</title>
  <updated>2014-04-17T15:40:51+02:00</updated>
  <link href="http://normanmaurer.me/blog.atom" rel="self" type="application/atom+xml" />
  <link href="http://normanmaurer.me/" rel="alternate" type="text/html" />
  <entry>
    <id>http://normanmaurer.me/blog/2014/04/17/Reactive-Streams/</id>
    <title>Reactive Streams</title>
    <updated>2014-04-17T15:40:51+02:00</updated>
    <published>2014-04-17T00:00:00+00:00</published>
    <link href="http://normanmaurer.me/blog/2014/04/17/Reactive-Streams/" rel="alternate" type="text/html" />
    <author>
      <name>normanmaurer</name>
    </author>
    <summary>
      
      As some of you may hopefully noticed, today Reactive Streams was announced and left stealth-mode. The idea of the Reactive Streams project is to provide a well defined SPI/API for asynchronous processing of data with back pressure built in. This will make it quite easy to bridge different asynchronous frameworks together and so pass data from one to the other and vice versa.  And all will backpressure etc working out of the box without the need to have it implement by the user himself. 
      
      Vert.x and Reactive Streams
      As Vert.x is one of these asynchronous frameworks / platforms that runs...
    </summary>
    <content type="html">
      
      &lt;p&gt;As some of you may hopefully noticed, today &lt;a href=&quot;http://www.reactive-streams.org&quot;&gt;Reactive Streams&lt;/a&gt; was announced and left stealth-mode. The idea of the &lt;a href=&quot;http://www.reactive-streams.org&quot;&gt;Reactive Streams&lt;/a&gt; project is to provide a well defined SPI/API for asynchronous processing of data with back pressure built in. This will make it quite easy to bridge different asynchronous frameworks together and so pass data from one to the other and vice versa.  And all will backpressure etc working out of the box without the need to have it implement by the user himself. &lt;/p&gt;
      
      &lt;h1 id=&quot;vertx-and-reactive-streams&quot;&gt;Vert.x and Reactive Streams&lt;/h1&gt;
      &lt;p&gt;As &lt;a href=&quot;http://vertx.io&quot;&gt;Vert.x&lt;/a&gt; is one of these asynchronous frameworks / platforms that runs on the JVM we are already working on a prototype that allows &lt;a href=&quot;http://vertx.io&quot;&gt;Vert.x&lt;/a&gt; to be used with the propsed SPI/API. While the prototype is currently mainly focused on the AsyncFile I'm quite certain that other areas of &lt;a href=&quot;http://vertx.io&quot;&gt;Vert.x&lt;/a&gt; will follow once all the details are worked out and the SPI/API has stabilized.&lt;/p&gt;
      
      &lt;p&gt;Providing such a unified abstraction offers a lot of freedom to the user and simplifies the use of different projects that implement it.&lt;/p&gt;
      
      &lt;p&gt;For example once &lt;a href=&quot;http://vertx.io&quot;&gt;Vert.x&lt;/a&gt;, &lt;a href=&quot;http://akka.io&quot;&gt;Akka&lt;/a&gt;, &lt;a href=&quot;https://github.com/Netflix/RxJava&quot;&gt;RxJava&lt;/a&gt; and &lt;a href=&quot;https://github.com/reactor/reactor&quot;&gt;Reactor&lt;/a&gt; all support it, passing data from one to the others would be as easy as here: &lt;/p&gt;
      
      &lt;pre class=&quot;syntax java&quot;&gt;
      vertx.fileSystem().open(&quot;/path/to/file&quot;, new Handler&amp;lt;AsyncResult&amp;lt;AsyncFile&amp;gt;&amp;gt;() {
          @Override
          public void handle(AsyncResult&amp;lt;AsyncFile&amp;gt; result) {
              if (result.successed()) {
                  AsyncFile file = result.result();
                  file.produceTo(akkaStream).produceTo(rxjavaObservable).produceTo(reactorStream);
              } else {
                  // handle error
              }
          }
      });
      &lt;/pre&gt;
      
      &lt;p&gt;All this processing is handled in an async manner and back pressure is applied. So stay tuned for more news on Reactive Streams, exciting times ahead.&lt;/p&gt;
      
      &lt;h1 id=&quot;so-what-&quot;&gt;So what ?&lt;/h1&gt;
      &lt;p&gt;Being part of such a movement is a big honour for me and I am looking forward to help shape the future of asynchronous processing. Special thanks to &lt;a href=&quot;https://www.typesafe.com&quot;&gt;Typesafe&lt;/a&gt; for driving the effort at the first place and &lt;a href=&quot;http://www.redhat.com&quot;&gt;Red Hat&lt;/a&gt; for allowing me to spend time on it.&lt;/p&gt;
    </content>
  </entry>
  <entry>
    <id>http://normanmaurer.me/blog/2014/01/07/JNI-Performance-Welcome-to-the-dark-side/</id>
    <title>JNI Performance - Welcome to the dark side</title>
    <updated>2014-04-17T15:40:51+02:00</updated>
    <published>2014-01-07T00:00:00+00:00</published>
    <link href="http://normanmaurer.me/blog/2014/01/07/JNI-Performance-Welcome-to-the-dark-side/" rel="alternate" type="text/html" />
    <author>
      <name>normanmaurer</name>
    </author>
    <summary>
      
      During the Holidays I finally found the mood to take on a task that has been on the to-do list for too long (I was talking about it since 2012 - anyway better late then never). The plan was to implement a native netty transport which doesn't use java.nio, but directly makes use of C and JNI and uses edge-triggered epoll, which is only available on linux. 
      
      
        Seriously ?
      
      
      Yeah&#8230; The idea was to write a transport implementation that outperforms what ships with java.nio by making optimal use of the Thread-Model that powers Netty and is optimized for linux....
    </summary>
    <content type="html">
      
      &lt;p&gt;During the Holidays I finally found the mood to take on a task that has been on the to-do list for too long (I was talking about it since 2012 - anyway better late then never). The plan was to implement a native &lt;a href=&quot;http://netty.io&quot;&gt;netty&lt;/a&gt; transport which doesn't use &lt;code&gt;java.nio&lt;/code&gt;, but directly makes use of C and JNI and uses edge-triggered &lt;a href=&quot;http://man7.org/linux/man-pages/man7/epoll.7.html&quot;&gt;epoll&lt;/a&gt;, which is only available on linux. &lt;/p&gt;
      
      &lt;blockquote&gt;
        &lt;p&gt;Seriously ?&lt;/p&gt;
      &lt;/blockquote&gt;
      
      &lt;p&gt;Yeah&amp;#8230; The idea was to write a transport implementation that outperforms what ships with &lt;code&gt;java.nio&lt;/code&gt; by making optimal use of the Thread-Model that powers Netty and is optimized for linux. Also, I wanted to practice my C and JNI skills again, as they felt a bit rusty. This blog post will talk about some performance issues related to JNI and other pitfalls that I encountered while working on the transport.&lt;/p&gt;
      
      &lt;p&gt;I will write up an extra post about the transport itself once it is opensourced, which will be in the next few weeks. In short, it outperforms the other netty transport which uses java.nio. This comes as no surprise as the provided one by java.nio must be more generic than what I needed for netty and linux.&lt;/p&gt;
      
      &lt;p&gt;Let me welcome you to the dark side!&lt;/p&gt;
      
      &lt;p&gt;&lt;img src=&quot;http://normanmaurer.me/blog/images/dark_side.jpg&quot; alt=&quot;AtomicExample&quot; title=&quot;Welcome to the dark side!&quot;&gt;&lt;/p&gt;
      
      &lt;p&gt;&lt;a href=&quot;http://www.flickr.com/photos/isherwoodchris/7074633375/&quot;&gt;Chris Isherwood&lt;/a&gt;&lt;/p&gt;
      
      &lt;p&gt;There are a few techniques you can use to improve the performance. These sections will cover them&amp;#8230; &lt;/p&gt;
      
      &lt;h2 id=&quot;caching-jmethodid-jfieldid-and-jclass&quot;&gt;Caching jmethodID, jfieldID and jclass&lt;/h2&gt;
      &lt;p&gt;When you work with JNI you often need to either access a method of a java object (&lt;code&gt;jobject&lt;/code&gt;) or a field which holds some value.
      Also, you often need to get the class (jclass) to instantiate a new Object and return it from within your JNI call. All of this means you will need to make a &quot;lookup&quot; to get access to the needed &lt;code&gt;jmethodID&lt;/code&gt;, &lt;code&gt;jfieldID&lt;/code&gt; or &lt;code&gt;jclass&lt;/code&gt;. But this doesn't come for free. Each lookup takes time and so affects performance if you are kicking the tires hard enough.&lt;/p&gt;
      
      &lt;p&gt;Luckily enough, there is a solution: caching.&lt;/p&gt;
      
      &lt;p&gt;Caching of &lt;code&gt;jmethodID&lt;/code&gt; and &lt;code&gt;jfieldID&lt;/code&gt; is straight forward. All you need to do is lookup the &lt;code&gt;jmethodID&lt;/code&gt; or &lt;code&gt;jfieldID&lt;/code&gt; and store it in a global field.&lt;/p&gt;
      
      &lt;pre class=&quot;syntax clang&quot;&gt;
      jmethodID limitMethodId;
      jfieldID limitFieldId;
      
      // Is automatically called once the native code is loaded via System.loadLibary(...);
      jint JNI_OnLoad(JavaVM* vm, void* reserved) {
          JNIEnv* env;
          if ((*vm)-&amp;gt;GetEnv(vm, (void **) &amp;amp;env, JNI_VERSION_1_6) != JNI_OK) {
              return JNI_ERR;
          } else {
              jclass cls = (*env)-&amp;gt;FindClass(&quot;java/nio/Buffer&quot;);
              // Get the id of the Buffer.limit() method.
              limitMethodId = (*env)-&amp;gt;GetMethodID(env, cls, &quot;limit&quot;, &quot;()I&quot;);
      
              // Get int limit field of Buffer
              limitFieldId = (*env)-&amp;gt;GetFieldID(env, cls, &quot;limit&quot;, &quot;I&quot;);
          }
      }&lt;/pre&gt;
      
      &lt;p&gt;This way, every time you need to either access the field or the method you can just reuse the global &lt;code&gt;jmethodID&lt;/code&gt; and &lt;code&gt;jfieldID&lt;/code&gt;. This is safe even from different threads. You may be tempted to do the same with &lt;code&gt;jclass&lt;/code&gt;, and it may work at first, but then bombs out later. This is because jclass is handled as a local reference and so can be recycled by the GC. &lt;/p&gt;
      
      &lt;p&gt;There is a solution, however, which will allow you to cache the &lt;code&gt;jclass&lt;/code&gt; and eliminate subsequent lookups. JNI provides special methods to &quot;convert&quot; a local reference to a global one which is guaranteered to not be GC'ed until it is explicitly removed. For example:&lt;/p&gt;
      
      &lt;pre class=&quot;syntax clang&quot;&gt;
      jclass bufferCls;
      
      // Is automatically called once the native code is loaded via System.loadLibary(...);
      jint JNI_OnLoad(JavaVM* vm, void* reserved) {
          JNIEnv* env;
          if ((*vm)-&amp;gt;GetEnv(vm, (void **) &amp;amp;env, JNI_VERSION_1_6) != JNI_OK) {
              return JNI_ERR;
          } else {
              jclass localBufferCls = (*env)-&amp;gt;FindClass(env, &quot;java/nio/ByteBuffer&quot;);
              bufferCls = (jclass) (*env)-&amp;gt;NewGlobalRef(env, localBufferCls);
          }
      }
      
      // Is automatically called once the Classloader is destroyed
      void JNI_OnUnload(JavaVM *vm, void *reserved) {
          JNIEnv* env;
          if ((*vm)-&amp;gt;GetEnv(vm, (void **) &amp;amp;env, JNI_VERSION_1_6) != JNI_OK) {
              // Something is wrong but nothing we can do about this :(
              return;
          } else {
              // delete global references so the GC can collect them
              if (bufferCls != NULL) {
                  (*env)-&amp;gt;DeleteGlobalRef(env, bufferCls);
              }
          }
      }&lt;/pre&gt;
      &lt;p&gt;Please note the explicit free of the global reference by calling `DeleteGlobalRef(&amp;#8230;). This is needed to prevent a memory leak as the GC is not allowed to release it. So remember this!&lt;/p&gt;
      
      &lt;h2 id=&quot;crossing-the-borders&quot;&gt;Crossing the borders&lt;/h2&gt;
      &lt;p&gt;Typically, you have some native code which calls from java into your C code, but there are sometimes also situations where you need to access some data from your C (JNI) code that is stored in the java object itself. For this, you can call &quot;back&quot; into java from within the C code. One problem that is often overlooked is the performance hit it takes to cross the border. This is especially true when you call back from C into java.  &lt;/p&gt;
      
      &lt;p&gt;The same problem hit me hard when I implemented the writev method of my native transport. This method basically takes an array of &lt;code&gt;ByteBuffer&lt;/code&gt; objects and tries to write them via gathering writes for performances reasons. My first approach was to lookup the &lt;code&gt;ByteBuffer.limit()&lt;/code&gt; and &lt;code&gt;ByteBuffer.position()&lt;/code&gt; methods and cache their `jmethodID's as explained before. This yielded the following:&lt;/p&gt;
      
      &lt;pre class=&quot;syntax clang&quot;&gt;
      JNIEXPORT jlong JNICALL Java_io_netty_jni_internal_Native_writev(JNIEnv * env, jclass clazz, jint fd, jobjectArray buffers, jint offset, jint length) {
          struct iovec iov[length];
          int i;
          int iovidx = 0;
          for (i = offset; i &amp;lt; length; i++) {
              jobject bufObj = (*env)-&amp;gt;GetObjectArrayElement(env, buffers, i);
              jint pos = (*env)-&amp;gt;CallIntMethod(env, bufObj, posId, NULL);
      
              jint limit = (*env)-&amp;gt;CallIntMethod(env, bufObj, limitId, NULL);
              void *buffer = (*env)-&amp;gt;GetDirectBufferAddress(env, bufObj);
              iov[iovidx].iov_base = buffer + pos;
              iov[iovidx].iov_len = limit - pos;
              iovidx++;
          }
          ...
          // code to write to the fd 
          ...
      }&lt;/pre&gt;
      
      &lt;p&gt;After the first benchmark, I was wondering why the speed was not matching my expections. I was only able to get about &lt;em&gt;530k req/sec&lt;/em&gt; with the following command against my webserver implementation: &lt;/p&gt;
      
      &lt;pre&gt;&lt;code&gt;# wrk-pipeline -H 'Host: localhost' -H 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8' -H 'Connection: keep-alive' -d 120 -c 256 -t 8 --pipeline 16 http://127.0.0.1:8080/plaintext
      &lt;/code&gt;&lt;/pre&gt;
      
      &lt;p&gt;After more thinking, I suspected that calling back into java code so often during the loop was the cause of the problems. So I checked the openjdk source code to find the names of the actual fields that hold the limit and position values. I changed my code as follows:&lt;/p&gt;
      
      &lt;pre class=&quot;syntax clang&quot;&gt;
      JNIEXPORT jlong JNICALL Java_io_netty_jni_internal_Native_writev(JNIEnv * env, jclass clazz, jint fd, jobjectArray buffers, jint offset, jint length) {
          struct iovec iov[length];
          int i;
          int iovidx = 0;
          for (i = offset; i &amp;lt; length; i++) {
              jobject bufObj = (*env)-&amp;gt;GetObjectArrayElement(env, buffers, i);
              jint pos = (*env)-&amp;gt;GetIntField(env, bufObj, posFieldId);
      
              jint limit = (*env)-&amp;gt;GetIntField(env, bufObj, limitFieldId);
              void *buffer = (*env)-&amp;gt;GetDirectBufferAddress(env, bufObj);
              iov[iovidx].iov_base = buffer + pos;
              iov[iovidx].iov_len = limit - pos;
              iovidx++;
          }
          ...
           // code to write to the fd 
           ...
      }&lt;/pre&gt;
      
      &lt;p&gt;This change resulted in a boost of about 63k req/sec for a total of about &lt;em&gt;593k req/sec&lt;/em&gt;! Not bad at all&amp;#8230; &lt;/p&gt;
      
      &lt;p&gt;Each benchmark iteration included a 20 minute warmup period followed by 3 runs of 2 minutes to gather the actual data.&lt;/p&gt;
      
      &lt;p&gt;The following graphs show the outcome in detail:&lt;/p&gt;
      
      &lt;p&gt;&lt;img src=&quot;http://normanmaurer.me/blog/images/jni_request_sec.png&quot; alt=&quot;RequestsPerSecond&quot; title=&quot;Requests per second&quot;&gt;&lt;/p&gt;
      
      &lt;p&gt;&lt;img src=&quot;http://normanmaurer.me/blog/images/jni_transfer_sec.png&quot; alt=&quot;TransferPerSecond&quot; title=&quot;Transfer (MB) per second&quot;&gt;&lt;/p&gt;
      
      &lt;p&gt;Lessons learned here are that crossing the border is quite expensive when you are pushing hard enough. The down-side of accessing the fields directly is that a change to the field itself will break your code.  In the actual code (which I will blog about and release soon), this is handled gracefully by falling back to using the methods if the fields aren't found, and logging a warning.&lt;/p&gt;
      
      &lt;h2 id=&quot;releasing-with-care&quot;&gt;Releasing with care&lt;/h2&gt;
      
      &lt;p&gt;When using JNI, you often have to convert from some of the various &lt;code&gt;j*Array&lt;/code&gt; instances to a pointer and release it again after you are done. So make sure all the changes are &quot;synced&quot; between the array you passed to the jni method and the pointer you used within the jni code. 
      When calling &lt;code&gt;Release*ArrayElements(...)&lt;/code&gt; you have to specify a mode to tell the JVM how it should handle the syncing of the array you passed in and the one used within your JNI code.&lt;/p&gt;
      
      &lt;p&gt;Different modes are:&lt;/p&gt;
      
      &lt;ul&gt;
        &lt;li&gt;
          &lt;p&gt;&lt;strong&gt;0&lt;/strong&gt;&lt;/p&gt;
      
          &lt;p&gt;Default: copy everything from the native array to the java array, and free the java array.&lt;/p&gt;
        &lt;/li&gt;
        &lt;li&gt;
          &lt;p&gt;&lt;strong&gt;JNI_ABORT&lt;/strong&gt;&lt;/p&gt;
      
          &lt;p&gt;Don't touch the java array but free it.&lt;/p&gt;
        &lt;/li&gt;
        &lt;li&gt;
          &lt;p&gt;&lt;strong&gt;JNI_COMMIT&lt;/strong&gt;&lt;/p&gt;
      
          &lt;p&gt;Copy everything from the native array to the java array, but don't free it. It must be freed later.&lt;/p&gt;
        &lt;/li&gt;
      &lt;/ul&gt;
      
      &lt;p&gt;Often people just use mode 0 as it is the &quot;safest&quot;. But using 0 when you actually don't need it gives you a performance penality. Why? 
      Mainly because using 0 will trigger an array copy all the time, but there are two situations where you won't need the array copy at all:&lt;/p&gt;
      
      &lt;ol&gt;
        &lt;li&gt;You are not changing the values in the array at all; only reading them.&lt;/li&gt;
        &lt;li&gt;The JVM returns a direct pointer to the java array which is pinned in memory. When this is the case, you won't need to copy the array over as you operate directly on the same data used by java itself. Whether or not the JVM does this depends on the JNI implementation. Because of this, you need to pass in a pointer to a jboolean when you obtain the elements. The value of this jboolean indicates whether a copy was made or if it is just pinned. &lt;/li&gt;
      &lt;/ol&gt;
      
      &lt;p&gt;The following code modifies the native array and then checks if it needs to copy the data back or not.&lt;/p&gt;
      
      &lt;pre class=&quot;syntax clang&quot;&gt;
      JNIEXPORT jint JNICALL Java_io_netty_jni_internal_Native_epollWait(JNIEnv * env, jclass clazz, jint efd, jlongArray events, jint timeout) {
          int len = (*env)-&amp;gt;GetArrayLength(env, events);
          struct epoll_event ev[len];
          int ready;
      
          // blocks until ev is filled and return if ready &amp;lt; 1.
          ....
      
          jboolean isCopy;
      
          jlong *elements = (*env)-&amp;gt;GetLongArrayElements(env, events, &amp;amp;isCopy);
          if (elements == NULL) {
              // No memory left ?!?!?
              throwOutOfMemoryError(env, &quot;Can't allocate memory&quot;);
              return return -1;
          }
          int i;
          for (i = 0; i &amp;lt; ready; i++) {
              elements[i] = ev[i].data.u64;
          }
              
          jint mode;
          // release again to prevent memory leak
          if (isCopy) {
              mode = 0;
          } else {
              // was just pinned so use JNI_ABORT to eliminate not needed copy.
              mode = JNI_ABORT;
          }
          (*env)-&amp;gt;ReleaseLongArrayElements(env, events, elements, mode);
       
          return ready;
      }&lt;/pre&gt;
      
      &lt;p&gt;Doing the isCopy check may save you an array copy, so it's a good practice. There are more JNI methods that allow you to specify a mode, for which this advice also applies.&lt;/p&gt;
      
      &lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
      &lt;p&gt;Hopefully, this post gave you some insight about JNI and the performance impact some operations have. The next post will cover the native transport for netty in detail, and give you some concrete numbers in terms of performance. So stay tuned &amp;#8230;.&lt;/p&gt;
      
      &lt;p&gt;Thanks again to &lt;a href=&quot;https://twitter.com/nitsanw&quot;&gt;Nitsan Wakart&lt;/a&gt; , &lt;a href=&quot;https://twitter.com/daschl&quot;&gt;Michael Nitschinger&lt;/a&gt; and &lt;a href=&quot;https://twitter.com/jcrossley3&quot;&gt;Jim Crossley&lt;/a&gt; for the review!&lt;/p&gt;
      
      &lt;h2 id=&quot;usefull-jni-links&quot;&gt;Usefull JNI Links&lt;/h2&gt;
      
      &lt;p&gt;&lt;a href=&quot;http://docs.oracle.com/javase/7/docs/technotes/guides/jni/spec/jniTOC.html&quot;&gt;Java Native Interface Specification&lt;/a&gt;&lt;/p&gt;
      
      &lt;p&gt;&lt;a href=&quot;https://thenewcircle.com/s/post/1292/jni_reference_example&quot;&gt;JNI Reference Example&lt;/a&gt;&lt;/p&gt;
      
      &lt;p&gt;&lt;a href=&quot;http://developer.android.com/training/articles/perf-jni.html&quot;&gt;JNI Tips&lt;/a&gt;&lt;/p&gt;
    </content>
  </entry>
  <entry>
    <id>http://normanmaurer.me/blog/2013/11/09/The-hidden-performance-costs-of-instantiating-Throwables/</id>
    <title>The hidden performance costs of instantiating Throwables</title>
    <updated>2014-04-17T15:40:51+02:00</updated>
    <published>2013-11-09T00:00:00+00:00</published>
    <link href="http://normanmaurer.me/blog/2013/11/09/The-hidden-performance-costs-of-instantiating-Throwables/" rel="alternate" type="text/html" />
    <author>
      <name>normanmaurer</name>
    </author>
    <summary>
      
      Today it's time to make you aware of the performance penalty you may pay when using Throwable, Error, Exception and as a result give you a better idea how to avoid it. You may never have thought about it, but using those in a wrong fashion can affect the performance of your applications to a large degree.
      
      Alright, let us start from scratch. You may have heard that you should only use Exception / Throwable / Error for exceptional situations (something that is not the norm and signals unexpected behaviour). This is actually a good advice, but even if you follow...
    </summary>
    <content type="html">
      
      &lt;p&gt;Today it's time to make you aware of the performance penalty you may pay when using &lt;code&gt;Throwable&lt;/code&gt;, &lt;code&gt;Error&lt;/code&gt;, &lt;code&gt;Exception&lt;/code&gt; and as a result give you a better idea how to avoid it. You may never have thought about it, but using those in a wrong fashion can affect the performance of your applications to a large degree.&lt;/p&gt;
      
      &lt;p&gt;Alright, let us start from scratch. You may have heard that you should only use &lt;code&gt;Exception&lt;/code&gt; / &lt;code&gt;Throwable&lt;/code&gt; / &lt;code&gt;Error&lt;/code&gt; for exceptional situations (something that is not the norm and signals unexpected behaviour). This is actually a good advice, but even if you follow it (which I really hope you do) there may be situations where you need to throw one.&lt;/p&gt;
      
      &lt;p&gt;Throwing a &lt;code&gt;Throwable&lt;/code&gt; (or one of it's subtypes) is not a big deal. Well it's not for free, but still not the main cause for peformance issues. The real issue comes up when you create the object itself.&lt;/p&gt;
      
      &lt;blockquote&gt;
        &lt;p&gt;Huh?&lt;/p&gt;
      &lt;/blockquote&gt;
      
      &lt;p&gt;So why is creating a &lt;code&gt;Throwable&lt;/code&gt; so expensive? Isn't it just a simple light-weight POJO? Simple yes, but certainly not light-weight! &lt;/p&gt;
      
      &lt;p&gt;It's because usally it will call &lt;code&gt;Throwable.fillInStackTrace()&lt;/code&gt;, which needs to look down the stack and put it in the newly created &lt;code&gt;Throwable&lt;/code&gt;. This can affect the performance of your application to a large degree if you create a lot of them.&lt;/p&gt;
      
      &lt;p&gt;&lt;strong&gt;But what to do about this?&lt;/strong&gt;&lt;/p&gt;
      
      &lt;p&gt;There are a few techniques you can use to improve the performance. Let's have a deeper look into them now.&lt;/p&gt;
      
      &lt;h2 id=&quot;lazy-create-a-throwable-and-reuse&quot;&gt;Lazy create a Throwable and reuse&lt;/h2&gt;
      &lt;p&gt;There are some situations where you would like to use the same &lt;code&gt;Throwable&lt;/code&gt; multiple times. In this case you can lazily create and then reuse it. This way you eliminate a lot of the initial overhead. &lt;/p&gt;
      
      &lt;p&gt;To make things more clear let's have a look at some real-world example. In this example we assume that we have a list of pending writes which are all failed because the underlying &lt;code&gt;Channel&lt;/code&gt; was closed. &lt;/p&gt;
      
      &lt;p&gt;The pending writes are represented by the &lt;code&gt;PendingWrite&lt;/code&gt; interface as shown below.&lt;/p&gt;
      
      &lt;pre class=&quot;syntax java&quot;&gt; 
      public interface PendingWrite {
          void setSuccess();
          void setFailure(Throwable cause);
      }&lt;/pre&gt;
      
      &lt;p&gt;We have a &lt;code&gt;Writer&lt;/code&gt; class which will need to fail all &lt;code&gt;PendingWrite&lt;/code&gt; instances with a &lt;code&gt;ClosedChannelException&lt;/code&gt;. You may be tempted to implement it like this:&lt;/p&gt;
      
      &lt;pre class=&quot;syntax java&quot;&gt;  
      public class Writer {
             
          ....
      
          private void failPendingWrites(PendingWrite... writes) {
              for (PendingWrite write: writes) {
                  write.setFailure(new ClosedChannelException());
              }    
          }
      }&lt;/pre&gt;
      
      &lt;p&gt;This works, but if this method is called often and with a not to small array of &lt;code&gt;PendingWrite&lt;/code&gt;s you are in serious trouble. It will need to fill in the stacktrace for every &lt;code&gt;PendingWrite&lt;/code&gt; you are about to fail!&lt;/p&gt;
      
      &lt;p&gt;This is not only very wasteful but also something that is easy to optimize, so let's bring it on…&lt;/p&gt;
      
      &lt;p&gt;The key is to lazy create the &lt;code&gt;ClosedChannelException&lt;/code&gt; and reuse it for each &lt;code&gt;PendingWrite&lt;/code&gt; that needs to get failed. And doing so will even result in the correct stacktrace to be filled in… &lt;strong&gt;JackPot!&lt;/strong&gt;&lt;/p&gt;
      
      &lt;p&gt;So fixing this is as easy as rewriting the &lt;code&gt;failPendingWrites(...)&lt;/code&gt; method as shown here:&lt;/p&gt;
      
      &lt;pre class=&quot;syntax java&quot;&gt;
      public class Writer {
          ....
      
          private void failPendingWrites(PendingWrite... writes) {
              if (writes.length == 0) {
                  return;
              }
              ClosedChannelException error = new ClosedChannelException();
              for (PendingWrite write: writes) {
                  write.setFailure(error);
              }
          }
      }&lt;/pre&gt;
      
      &lt;p&gt;Notice we lazily create the &lt;code&gt;ClosedChannelException&lt;/code&gt; only if needed (if we have something to fail) and reuse the same instance for all the &lt;code&gt;PendingWrite&lt;/code&gt;s in the array. This will dramatically cut down the overhead, but you can reduce it even more with some tradeoff which I will explain next…&lt;/p&gt;
      
      &lt;h2 id=&quot;use-static-throwable-with-no-stacktrace-at-all&quot;&gt;Use static Throwable with no stacktrace at all&lt;/h2&gt;
      &lt;p&gt;Sometimes you may not need a stacktrace at all as the &lt;code&gt;Throwable&lt;/code&gt; itself is enough information for what's going on. In this case, you are able to just use a static &lt;code&gt;Throwable&lt;/code&gt; and reuse it.&lt;/p&gt;
      
      &lt;p&gt;What you should remember in this case is to set the stacktrace to an empty array to not have some &quot;wrong&quot; stacktrace show up, and so cause a lot of headache when debugging.&lt;/p&gt;
      
      &lt;p&gt;Let us see how this fit in again in our &lt;code&gt;Writer&lt;/code&gt; class:&lt;/p&gt;
      
      &lt;pre class=&quot;syntax java&quot;&gt;
      public class Writer {
          private static final ClosedChannelException CLOSED_CHANNEL_EXCEPTION = new ClosedChannelException();
          static {
              CLOSED_CHANNEL_EXCEPTION.setStackTrace(new StackTraceElement[0]);
          }
          ....
      
          private void failPendingWrites(PendingWrite... writes) {
              for (PendingWrite write: writes) {
                  write.setFailure(CLOSED_CHANNEL_EXCEPTION);
              }
          }
      }&lt;/pre&gt;
      
      &lt;p&gt;But where is this useful? &lt;/p&gt;
      
      &lt;p&gt;For example in a network application a closed &lt;code&gt;Channel&lt;/code&gt; is not a really exceptional state anyway. So this may be a good fit in this case. In fact we do something similar in &lt;a href=&quot;http://netty.io&quot;&gt;Netty&lt;/a&gt; for exactly this case.&lt;/p&gt;
      
      &lt;p&gt;&lt;strong&gt;Caution: only do this if you are sure you know what you are doing!&lt;/strong&gt;&lt;/p&gt;
      
      &lt;h2 id=&quot;benchmarks&quot;&gt;Benchmarks&lt;/h2&gt;
      &lt;p&gt;Now with all the claims it's time to actually proof them. For this I wrote a microbenchmark using &lt;a href=&quot;http://openjdk.java.net/projects/code-tools/jmh/&quot;&gt;JMH&lt;/a&gt;. &lt;/p&gt;
      
      &lt;p&gt;You can find the source code of the benchmark in the &lt;a href=&quot;https://github.com/normanmaurer/jmh-benchmarks/tree/master/src/main/java/me/normanmaurer/benchmarks&quot;&gt;github repository&lt;/a&gt;.
      As there is no JMH version in any public maven repository yet I just bundled a SNAPSHOT version of it in the repository. As this is just a SNAPSHOT it may get out of date at some point in time…. Anyway this is good enough for us to run a benchmark and should be quite simple to be updated if needed.&lt;/p&gt;
      
      &lt;p&gt;This benchmark was run with:&lt;/p&gt;
      
      &lt;pre&gt;&lt;code&gt;# git clone https://github.com/normanmaurer/jmh-benchmarks.git
      # cd jmh-benchmarks
      ➜  jmh-benchmarks git:(master) ✗ mvn clean package
      ➜  jmh-benchmarks git:(master) ✗ java -jar target/microbenchmarks.jar -w 10 -wi 3 -i 3 -of csv -o output.csv -odr &quot;.*ThrowableBenchmark.*&quot;
      &lt;/code&gt;&lt;/pre&gt;
      
      &lt;p&gt;This basically means:&lt;/p&gt;
      
      &lt;ul&gt;
        &lt;li&gt;Clone the code&lt;/li&gt;
        &lt;li&gt;Build it the code&lt;/li&gt;
        &lt;li&gt;Run a warmup for 10 seconds&lt;/li&gt;
        &lt;li&gt;Run warmup 3 times&lt;/li&gt;
        &lt;li&gt;Run each benchmark 3 times&lt;/li&gt;
        &lt;li&gt;Generate output as csv&lt;/li&gt;
      &lt;/ul&gt;
      
      &lt;p&gt;The benchmark result contains the ops/msec. Each op represents the call of &lt;code&gt;failPendingWrites(...)&lt;/code&gt; with and array of 10000 &lt;code&gt;PendingWrite&lt;/code&gt;s.&lt;/p&gt;
      
      &lt;p&gt;Enough said, time to look at the outcome:&lt;/p&gt;
      
      &lt;p&gt;&lt;img src=&quot;http://normanmaurer.me/blog/images/benchmark_throwable.png&quot; alt=&quot;Throwable&quot; title=&quot;Benchmark of different usage of Throwable&quot;&gt;&lt;/p&gt;
      
      &lt;p&gt;As you can see here creating a new &lt;code&gt;Throwable&lt;/code&gt; is by far the slowest way to handle it. Next one is to lazily create a &lt;code&gt;Throwable&lt;/code&gt; and reuse it for the whole method invocation. The winner is to reuse a static &lt;code&gt;Throwable&lt;/code&gt; with the drawback of not having any stacktrace. So I think it's fair to say using a lazy created &lt;code&gt;Throwable&lt;/code&gt; is the way to go in most cases. If you really need the last 1 % performance you could also make use of the static solution but will loose the stacktrace for debugging. So you see it's always a tradeoff.&lt;/p&gt;
      
      &lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
      &lt;p&gt;You should be aware of how expensive &lt;code&gt;Throwable.fillInStackTrace()&lt;/code&gt; is and so think hard about how and when you create new instances of &lt;code&gt;Throwable&lt;/code&gt;. This is also true for subtypes as those will call the super constructor.&lt;/p&gt;
      
      &lt;p&gt;To make it short, nothing is for free so think about what you are doing before you run into performance problems later.
      Another good read on this topic is &lt;a href=&quot;https://blogs.oracle.com/jrose/entry/longjumps_considered_inexpensive&quot;&gt;the blog post of John Rose&lt;/a&gt;.&lt;/p&gt;
      
      &lt;p&gt;Thanks again to &lt;a href=&quot;https://twitter.com/nitsanw&quot;&gt;Nitsan Wakart&lt;/a&gt; and &lt;a href=&quot;https://twitter.com/daschl&quot;&gt;Michael Nitschinger&lt;/a&gt; for the review!&lt;/p&gt;
    </content>
  </entry>
  <entry>
    <id>http://normanmaurer.me/blog/2013/10/28/Lesser-known-concurrent-classes-Part-1/</id>
    <title>Lesser known concurrent classes - Atomic*FieldUpdater</title>
    <updated>2014-04-17T15:40:51+02:00</updated>
    <published>2013-10-28T00:00:00+00:00</published>
    <link href="http://normanmaurer.me/blog/2013/10/28/Lesser-known-concurrent-classes-Part-1/" rel="alternate" type="text/html" />
    <author>
      <name>normanmaurer</name>
    </author>
    <summary>
      
      Today I want to talk about one of the lesser known utility classes when it comes to atomic operations in Java. Everyone who ever has done some real work with the java.util.concurrent package should be aware of the Atomic* classes in there which helps you to do atomic operations on references, Longs, Integers, Booleans and more.
      
      The classes in question are all located in the java.util.concurrent.atomic package. 
      Like:
      
      
        AtomicBoolean
        AtomicInteger
        AtomicReference
        AtomicLong 
        ….
      
      
      Using those is as easy as doing something like:
      &lt;pre class="syntax java"&gt;
      AtomicLong atomic = new AtomicLong(0);
      atomic.compareAndSet(0, 1);
      …
      …
      &lt;/pre&gt;
      
      So what is the big deal with them?...
    </summary>
    <content type="html">
      
      &lt;p&gt;Today I want to talk about one of the lesser known utility classes when it comes to atomic operations in Java. Everyone who ever has done some real work with the &lt;code&gt;java.util.concurrent&lt;/code&gt; package should be aware of the Atomic* classes in there which helps you to do atomic operations on references, Longs, Integers, Booleans and more.&lt;/p&gt;
      
      &lt;p&gt;The classes in question are all located in the &lt;a href=&quot;http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/atomic/package-summary.html&quot;&gt;java.util.concurrent.atomic package&lt;/a&gt;. 
      Like:&lt;/p&gt;
      
      &lt;ul&gt;
        &lt;li&gt;&lt;code&gt;AtomicBoolean&lt;/code&gt;&lt;/li&gt;
        &lt;li&gt;&lt;code&gt;AtomicInteger&lt;/code&gt;&lt;/li&gt;
        &lt;li&gt;&lt;code&gt;AtomicReference&lt;/code&gt;&lt;/li&gt;
        &lt;li&gt;
      &lt;code&gt;AtomicLong&lt;/code&gt; &lt;/li&gt;
        &lt;li&gt;….&lt;/li&gt;
      &lt;/ul&gt;
      
      &lt;p&gt;Using those is as easy as doing something like:
      &amp;lt;pre class=&quot;syntax java&quot;&amp;gt;
      AtomicLong atomic = new AtomicLong(0);
      atomic.compareAndSet(0, 1);
      …
      …
      &amp;lt;/pre&amp;gt;&lt;/p&gt;
      
      &lt;p&gt;So what is the big deal with them? It's about memory usage … 
      Wouldn't it be nice to be able to just use a &lt;code&gt;volatile long&lt;/code&gt;, save a object allocation and as a result use less memory? &lt;/p&gt;
      
      &lt;blockquote&gt;
        &lt;p&gt;HELL YEAH!&lt;/p&gt;
      &lt;/blockquote&gt;
      
      &lt;p&gt;This is exactly where the not widely known Atomic*FieldUpdater comes in. Those allow you to do &quot;atomic&quot; operations on a volatile field and so save the space which is needed to hold the object that you would create if you would use something like &lt;code&gt;AtomicLong&lt;/code&gt;. This works as Atomic*FieldUpdater is used as a static field and so not need to create a new Object everytime.&lt;/p&gt;
      
      &lt;blockquote&gt;
        &lt;p&gt;Neat, isn't it ?&lt;/p&gt;
      &lt;/blockquote&gt;
      
      &lt;p&gt;So to replace the above usage of &lt;code&gt;AtomicLong&lt;/code&gt; your code would look like:&lt;/p&gt;
      
      &lt;pre class=&quot;syntax java&quot;&gt;
      private static final AtomicLongFieldUpdater&amp;lt;TheDeclaringClass&amp;gt; ATOMIC_UPDATER =
              AtomicLongFieldUpdater.newUpdater(TheDeclaringClass.class, &quot;atomic&quot;);
      
      private volatile long atomic;
      
      public void yourMethod() {
          ATOMIC_UPDATER.compareAndSet(this, 0, 1);
          ...
          ...
      }&lt;/pre&gt;
      
      &lt;p&gt;This works with some reflection magic which is used when you create the &lt;code&gt;AtomicLongFieldUpdater&lt;/code&gt; instance. The field names passed in as argument (in this case atomic) will be used to lookup the declared volatile field. Thus you must be sure it matches. 
      And this is one of the weak things when using Atomic*FieldUpdater as there is no way for the compiler to detect that those match. So you need to keep an eye on this by yourself. &lt;/p&gt;
      
      &lt;p&gt;You may ask you self about if it worth it at all? As always it depends… If you only create a few thousands instances of the class that use Atomic* it may not worth it at all. But there may be situations where you need to create millions of them and keep the alive for a long time. In those situations it can have a big impact.&lt;/p&gt;
      
      &lt;p&gt;In the case of the &lt;a href=&quot;http://netty.io&quot;&gt;Netty Project&lt;/a&gt; we used &lt;code&gt;AtomicLong&lt;/code&gt; and &lt;code&gt;AtomicReference&lt;/code&gt; in our &lt;code&gt;Channel&lt;/code&gt;, &lt;code&gt;DefaultChannelPipeline&lt;/code&gt; and &lt;code&gt;DefaultChannelHandlerContext&lt;/code&gt; classes. A new instance of &lt;code&gt;Channel&lt;/code&gt; and &lt;code&gt;ChannelPipeline&lt;/code&gt; is created for each new connection that is accepted or established and it is not unusal to have 10  (or more ) &lt;code&gt;DefaultChannelHandlerContext&lt;/code&gt; objects per &lt;code&gt;DefaultChannelPipeline&lt;/code&gt;. For Non-Blocking Servers it is not unusal to handle a large amout of concurrent connections, which in our case was creating many instances of the mentioned classes. Those stayed alive for a long time as connections may be long-living. One of our users was testing 1M+ concurrent connections and saw a large amount of the heap space taken up because of the &lt;code&gt;AtomicLong&lt;/code&gt; and &lt;code&gt;AtomicReference&lt;/code&gt; instances we were using. By replacing those with AtomicField*Updater we were able to save about 500 MB of memory which, in combination with other changes, reduced the memory footprint by 3 GB.&lt;/p&gt;
      
      &lt;p&gt;For more details on the specific enhancements please have a look at those two issues: &lt;a href=&quot;https://github.com/netty/netty/issues/920&quot;&gt;#920&lt;/a&gt; and &lt;a href=&quot;https://github.com/netty/netty/issues/995&quot;&gt;#995&lt;/a&gt;&lt;/p&gt;
      
      &lt;p&gt;On thing to note is that there is no &lt;code&gt;AtomicBooleanFieldUpdater&lt;/code&gt; that you could use to replace a &lt;code&gt;AtomicBoolean&lt;/code&gt;. This is not a problem, just use &lt;code&gt;AtomicIntegerFieldUpdater&lt;/code&gt; with value 0 as false and 1 as true. Problem solved ;)&lt;/p&gt;
      
      &lt;h2 id=&quot;gimme-some-numbers&quot;&gt;Gimme some numbers&lt;/h2&gt;
      &lt;p&gt;Now with some theory behind us, let's proof our claim. Let us do a simple test here: we create a Class which will contain 10 &lt;code&gt;AtomicLong&lt;/code&gt; and 10 &lt;code&gt;AtomicReference&lt;/code&gt; instances and instantiate itself 1M times. This resembles the pattern we saw within &lt;a href=&quot;http://netty.io&quot;&gt;Netty&lt;/a&gt;.&lt;/p&gt;
      
      &lt;p&gt;Let us first have a look at the actual code:&lt;/p&gt;
      
      &lt;pre class=&quot;syntax java&quot;&gt;
      public class AtomicExample {
      
          final AtomicLong atomic1 = new AtomicLong(0);
          final AtomicLong atomic2 = new AtomicLong(0);
          final AtomicLong atomic3 = new AtomicLong(0);
          final AtomicLong atomic4 = new AtomicLong(0);
          final AtomicLong atomic5 = new AtomicLong(0);
          final AtomicLong atomic6 = new AtomicLong(0);
          final AtomicLong atomic7 = new AtomicLong(0);
          final AtomicLong atomic8 = new AtomicLong(0);
          final AtomicLong atomic9 = new AtomicLong(0);
          final AtomicLong atomic10 = new AtomicLong(0);
          final AtomicReference atomic11 = new AtomicReference&amp;lt;String&amp;gt;(&quot;String&quot;);
          final AtomicReference atomic12 = new AtomicReference&amp;lt;String&amp;gt;(&quot;String&quot;);
          final AtomicReference atomic13 = new AtomicReference&amp;lt;String&amp;gt;(&quot;String&quot;);
          final AtomicReference atomic14 = new AtomicReference&amp;lt;String&amp;gt;(&quot;String&quot;);
          final AtomicReference atomic15 = new AtomicReference&amp;lt;String&amp;gt;(&quot;String&quot;);
          final AtomicReference atomic16 = new AtomicReference&amp;lt;String&amp;gt;(&quot;String&quot;);
          final AtomicReference atomic17 = new AtomicReference&amp;lt;String&amp;gt;(&quot;String&quot;);
          final AtomicReference atomic18 = new AtomicReference&amp;lt;String&amp;gt;(&quot;String&quot;);
          final AtomicReference atomic19 = new AtomicReference&amp;lt;String&amp;gt;(&quot;String&quot;);
          final AtomicReference atomic20 = new AtomicReference&amp;lt;String&amp;gt;(&quot;String&quot;);
      
          public static void main(String[] args) throws Exception {
              List&amp;lt;AtomicExample&amp;gt; list = new LinkedList&amp;lt;AtomicExample&amp;gt;();
              for (int i = 0; i &amp;lt; 1000000; i++) {
                  list.add(new AtomicExample());
              }
              System.out.println(&quot;Created instances 1000000&quot;);
      
              System.in.read();
          }
      }&lt;/pre&gt;
      
      &lt;p&gt;You may think this is not very often the case in real world applications but just think about it for a bit. It may not be in one class but actually may be in many classes but which are still related. Like all of them are created for each new connection.&lt;/p&gt;
      
      &lt;p&gt;Now let us have a look at how much memory is retained by them. For this I used YourKit but any other tool which can inspect heap-dumps should just work fine.&lt;/p&gt;
      
      &lt;p&gt;&lt;img src=&quot;http://normanmaurer.me/blog/images/AtomicExample.png&quot; alt=&quot;AtomicExample&quot; title=&quot;Memory usage of AtomicExample&quot;&gt;&lt;/p&gt;
      
      &lt;p&gt;As you can see &lt;code&gt;AtomicLong&lt;/code&gt; and &lt;code&gt;AtomicReference&lt;/code&gt; instances took about about 400 MB of memory where &lt;code&gt;AtomicExample&lt;/code&gt; itself takes up 96MB. This makes up a a sum of ca. 500 MB memory that is used by each AtomicExample instance that is created.&lt;/p&gt;
      
      &lt;p&gt;Now let's do a second version of this class but replace &lt;code&gt;AtomicLong&lt;/code&gt; with &lt;code&gt;volatile long&lt;/code&gt; and &lt;code&gt;AtomicLongFieldUpdater&lt;/code&gt;. Beside this we also replace &lt;code&gt;AtomicReference&lt;/code&gt; with &lt;code&gt;volatile String&lt;/code&gt; and &lt;code&gt;AtomicReferenceFieldUpdater&lt;/code&gt;.&lt;/p&gt;
      
      &lt;p&gt;The code looks like this now:&lt;/p&gt;
      
      &lt;pre class=&quot;syntax java&quot;&gt;
      public class AtomicFieldExample {
      
          volatile long atomic1 = 0;
          volatile long atomic2 = 0;
          volatile long atomic3 = 0;
          volatile long atomic4 = 0;
          volatile long atomic5 = 0;
          volatile long atomic6 = 0;
          volatile long atomic7 = 0;
          volatile long atomic8 = 0;
          volatile long atomic9 = 0;
          volatile long atomic10 = 0;
          volatile String atomic11 = &quot;String&quot;;
          volatile String atomic12 = &quot;String&quot;;
          volatile String atomic13 = &quot;String&quot;;
          volatile String atomic14 = &quot;String&quot;;
          volatile String atomic15 = &quot;String&quot;;
          volatile String atomic16 = &quot;String&quot;;
          volatile String atomic17 = &quot;String&quot;;
          volatile String atomic18 = &quot;String&quot;;
          volatile String atomic19 = &quot;String&quot;;
          volatile String atomic20 = &quot;String&quot;;
      
          static final AtomicLongFieldUpdater&amp;lt;AtomicFieldExample&amp;gt; ATOMIC1_UPDATER = 
                  AtomicLongFieldUpdater.newUpdater(AtomicFieldExample.class, &quot;atomic1&quot;);
          static final AtomicLongFieldUpdater&amp;lt;AtomicFieldExample&amp;gt; ATOMIC2_UPDATER = 
                  AtomicLongFieldUpdater.newUpdater(AtomicFieldExample.class, &quot;atomic2&quot;);
          static final AtomicLongFieldUpdater&amp;lt;AtomicFieldExample&amp;gt; ATOMIC3_UPDATER = 
                  AtomicLongFieldUpdater.newUpdater(AtomicFieldExample.class, &quot;atomic3&quot;);
          static final AtomicLongFieldUpdater&amp;lt;AtomicFieldExample&amp;gt; ATOMIC4_UPDATER = 
                  AtomicLongFieldUpdater.newUpdater(AtomicFieldExample.class, &quot;atomic4&quot;);
          static final AtomicLongFieldUpdater&amp;lt;&amp;lt;AtomicFieldExample&amp;gt; ATOMIC5_UPDATER = 
                  AtomicLongFieldUpdater.newUpdater(AtomicFieldExample.class, &quot;atomic5&quot;);
          static final AtomicLongFieldUpdater&amp;lt;AtomicFieldExample&amp;gt; ATOMIC6_UPDATER = 
                  AtomicLongFieldUpdater.newUpdater(AtomicFieldExample.class, &quot;atomic6&quot;);
          static final AtomicLongFieldUpdater&amp;lt;AtomicFieldExample&amp;gt; ATOMIC7_UPDATER = 
                  AtomicLongFieldUpdater.newUpdater(AtomicFieldExample.class, &quot;atomic7&quot;);
          static final AtomicLongFieldUpdater&amp;lt;AtomicFieldExample&amp;gt; ATOMIC8_UPDATER = 
                  AtomicLongFieldUpdater.newUpdater(AtomicFieldExample.class, &quot;atomic8&quot;);
          static final AtomicLongFieldUpdater&amp;lt;AtomicFieldExample&amp;gt; ATOMIC9_UPDATER = 
                  AtomicLongFieldUpdater.newUpdater(AtomicFieldExample.class, &quot;atomic9&quot;);
          static final AtomicLongFieldUpdater&amp;lt;AtomicFieldExample&amp;gt; ATOMIC10_UPDATER = 
                  AtomicLongFieldUpdater.newUpdater(AtomicFieldExample.class, &quot;atomic10&quot;);
          static final AtomicReferenceFieldUpdater&amp;lt;AtomicFieldExample, String&amp;gt; ATOMIC11_UPDATER = 
                  AtomicReferenceFieldUpdater.newUpdater(AtomicFieldExample.class, String.class, &quot;atomic11&quot;);
          static final AtomicReferenceFieldUpdater&amp;lt;AtomicFieldExample, String&amp;gt;ATOMIC12_UPDATER = 
                  AtomicReferenceFieldUpdater.newUpdater(AtomicFieldExample.class, String.class, &quot;atomic12&quot;);
          static final AtomicReferenceFieldUpdater&amp;lt;AtomicFieldExample, String&amp;gt; ATOMIC13_UPDATER = 
                  AtomicReferenceFieldUpdater.newUpdater(AtomicFieldExample.class, String.class, &quot;atomic13&quot;);
          static final AtomicReferenceFieldUpdater&amp;lt;AtomicFieldExample, String&amp;gt; ATOMIC14_UPDATER = 
                  AtomicReferenceFieldUpdater.newUpdater(AtomicFieldExample.class, String.class, &quot;atomic14&quot;);
          static final AtomicReferenceFieldUpdater&amp;lt;AtomicFieldExample, String&amp;gt; ATOMIC15_UPDATER = 
                  AtomicReferenceFieldUpdater.newUpdater(AtomicFieldExample.class, String.class, &quot;atomic15&quot;);
          static final AtomicReferenceFieldUpdater&amp;lt;AtomicFieldExample, String&amp;gt; ATOMIC16_UPDATER = 
                  AtomicReferenceFieldUpdater.newUpdater(AtomicFieldExample.class, String.class, &quot;atomic16&quot;);
          static final AtomicReferenceFieldUpdater&amp;lt;AtomicFieldExample, String&amp;gt;ATOMIC17_UPDATER = 
                  AtomicReferenceFieldUpdater.newUpdater(AtomicFieldExample.class, String.class, &quot;atomic17&quot;);
          static final AtomicReferenceFieldUpdater&amp;lt;AtomicFieldExample, String&amp;gt; ATOMIC18_UPDATER = 
                  AtomicReferenceFieldUpdater.newUpdater(AtomicFieldExample.class, String.class, &quot;atomic18&quot;);
          static final AtomicReferenceFieldUpdater&amp;lt;AtomicFieldExample, String&amp;gt; ATOMIC19_UPDATER = 
                  AtomicReferenceFieldUpdater.newUpdater(AtomicFieldExample.class, String.class, &quot;atomic19&quot;);
          static final AtomicReferenceFieldUpdater&amp;lt;&amp;lt;AtomicFieldExample, String&amp;gt;ATOMIC20_UPDATER = 
                  AtomicReferenceFieldUpdater.newUpdater(AtomicFieldExample.class, String.class, &quot;atomic20&quot;);
      
          public static void main(String[] args) throws Exception {
              List&amp;lt;AtomicFieldExample&amp;gt; list = new LinkedList&amp;lt;&amp;lt;AtomicFieldExample&amp;gt;();
              for (int i = 0; i &amp;lt; 1000000; i++) {
                  list.add(new AtomicFieldExample());
              }
              System.out.println(&quot;Created instances 1000000&quot;);
      
              System.in.read();
          }
      }&lt;/pre&gt;
      
      &lt;p&gt;As you see the code becomes a bit more bloated, hopefully it pays out. Again let us take a look at the memory usage as before.&lt;/p&gt;
      
      &lt;p&gt;&lt;img src=&quot;http://normanmaurer.me/blog/images/AtomicFieldExample.png&quot; alt=&quot;AtomicFieldExample&quot; title=&quot;Memory usage of AtomicFieldExample&quot;&gt;&lt;/p&gt;
      
      &lt;p&gt;As you can see from the screenshot the memory footprint is a lot smaller. In fact it now needs not more then ca. 136MB of memory for the 1M instances of &lt;code&gt;AtomicFieldExample&lt;/code&gt;. This is a nice improvement compared to the baseline memory footprint. Now think about how much memory you can save if you have a few cases where you can replace Atomic* classes with volatile and Atomic*FieldUpdater in classes that are instanced a lot.&lt;/p&gt;
      
      &lt;p&gt;You may ask yourself why the &lt;code&gt;AtomicFieldExample&lt;/code&gt; is larger then the &lt;code&gt;AtomicExample&lt;/code&gt;. This is caused by the extra memory you need to store the references + longs. 
      &lt;code&gt;AtomicFieldExample&lt;/code&gt; has 10 longs + 10 references. This gives us:&lt;/p&gt;
      
      &lt;ul&gt;
        &lt;li&gt;10 * 8 bytes (for the longs)&lt;/li&gt;
        &lt;li&gt;10 * 4 bytes (for the references)&lt;/li&gt;
        &lt;li&gt;1 * 16 bytes (for itself)&lt;/li&gt;
      &lt;/ul&gt;
      
      &lt;p&gt;&lt;code&gt;AtomicExample&lt;/code&gt; has 20 refernces. This gives us:&lt;/p&gt;
      
      &lt;ul&gt;
        &lt;li&gt;20 * 4 bytes (for the references)&lt;/li&gt;
        &lt;li&gt;1 * 16 bytes (for itself)&lt;/li&gt;
      &lt;/ul&gt;
      
      &lt;p&gt;So it only pays off because we save the extra memory overhead of AtomicLong and AtomicReference itself. So to put it straight: &lt;strong&gt;Every Object has a fixed overhead&lt;/strong&gt;.&lt;/p&gt;
      
      &lt;p&gt;Beside the memory savings there are some other nice effect here, we did not mention before: &lt;/p&gt;
      
      &lt;ul&gt;
        &lt;li&gt;Because we save Objects the Garbage Collector has less overhead to care about, as it needs to keep track of every Object.&lt;/li&gt;
        &lt;li&gt;We save the tax of the built in monitor which comes as part of each Object&lt;/li&gt;
      &lt;/ul&gt;
      
      &lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
      
      &lt;p&gt;To summarize it, it may pay off to replace Atomic* objects with the corresponding volatile + Atomic*FieldUpdater. How much you save in terms of memory varies depending on what you replace. But the savings can be huge, especially when we talk about small &quot;Objects&quot;. &lt;/p&gt;
      
      &lt;p&gt;Let us do the maths again:&lt;/p&gt;
      
      &lt;ul&gt;
        &lt;li&gt;
      &lt;code&gt;AtomicLong&lt;/code&gt; = 24 bytes + 4 bytes (for the reference to it)&lt;/li&gt;
        &lt;li&gt;
      &lt;code&gt;volatile long&lt;/code&gt; = 8 bytes&lt;/li&gt;
      &lt;/ul&gt;
      
      &lt;p&gt;This gives us a saving of 16 bytes!&lt;/p&gt;
      
      &lt;h2 id=&quot;acknowledgements&quot;&gt;Acknowledgements&lt;/h2&gt;
      &lt;p&gt;Special thanks go out to &lt;a href=&quot;https://twitter.com/nitsanw&quot;&gt;Nitsan Wakart&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/daschl&quot;&gt;Michael Nitschinger&lt;/a&gt; and &lt;a href=&quot;https://twitter.com/tsunanet&quot;&gt;Benoît Sigoure&lt;/a&gt; for the review and feedback.&lt;/p&gt;
    </content>
  </entry>
</feed>
